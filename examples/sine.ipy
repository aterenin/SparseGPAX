%load_ext autoreload
%autoreload 2
import jax
import jax.numpy as jnp
import jax.random as jr
import jax.scipy as jsp
import tensorflow_probability
tfp = tensorflow_probability.experimental.substrates.jax
tfk = tfp.math.psd_kernels
import haiku as hk
from jax.experimental import optix
import sparsegpax

k = tfk.ExponentiatedQuadratic()
rng = hk.PRNGSequence(1)

model = hk.transform_with_state(lambda x: sparsegpax.SparseGaussianProcess(k, 1, 1, 11, 67, 17)(x))
prior = hk.transform_with_state(lambda x: sparsegpax.SparseGaussianProcess(k, 1, 1, 11, 67, 17).prior(x))
randomize = hk.transform_with_state(lambda: sparsegpax.SparseGaussianProcess(k, 1, 1, 11, 67, 17).randomize())
resample_prior_basis = hk.transform_with_state(lambda: sparsegpax.SparseGaussianProcess(k, 1, 1, 11, 67, 17).resample_prior_basis())
prior_kl = hk.transform_with_state(lambda: sparsegpax.SparseGaussianProcess(k, 1, 1, 11, 67, 17).prior_KL())
err_stddev = hk.transform_with_state(lambda: sparsegpax.SparseGaussianProcess(k, 1, 1, 11, 67, 17).err_stddev())
hyperprior = hk.transform_with_state(lambda: sparsegpax.SparseGaussianProcess(k, 1, 1, 11, 67, 17).hyperprior())

@jax.jit
def loss(params,state,key,x,y,n_data):
    (key_rnd,key_f) = jr.split(key,2)
    #
    (_,state) = randomize.apply(params,state,key_rnd)
    #
    (kl,_) = prior_kl.apply(params,state,jr.PRNGKey(0))
    #
    (f,_) = model.apply(params,state,key_f,x)
    (s,_) = err_stddev.apply(params,state,jr.PRNGKey(0))
    (n_samples,_,n_batch) = f.shape
    c = n_data / (n_batch * n_samples * 2)
    l = n_data*jnp.sum(jnp.log(s)) + c*jnp.sum(((y - f) / s)**2)
    #
    (r,_) = hyperprior.apply(params,state,jr.PRNGKey(0))
    #
    return kl + l + r

x = jnp.expand_dims(jnp.arange(-5,5.0000005,0.1), -1)
y = 2 * jnp.sin(x).T + jr.normal(next(rng), x.T.shape)/10

(params,state) = model.init(next(rng), x)
params = hk.data_structures.merge(params,{
    'sparse_gaussian_process': {
        'inducing_locations': jnp.expand_dims(jnp.arange(-5,5.0000005,1), -1)
        }
    })
(_,state) = resample_prior_basis.apply(params,state,next(rng))
(_,state) = randomize.apply(params,state,next(rng))


opt = optix.adam(0.01)
opt_state = opt.init(params)

for i in range(200):
    (train_loss,grads) = jax.value_and_grad(loss)(params,state,next(rng),x,y,x.shape[0])
    (updates,opt_state) = opt.update(grads, opt_state)
    params = optix.apply_updates(params,updates)
    print(i,"Loss:",train_loss)
